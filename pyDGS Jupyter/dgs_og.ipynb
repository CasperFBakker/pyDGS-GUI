{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys, os\n",
    "from imageio.v2 import imread\n",
    "import pywt\n",
    "from tqdm import tqdm\n",
    "from skimage.restoration import denoise_wavelet, estimate_sigma\n",
    "from functools import partial\n",
    "# rescale_sigma=True required to silence deprecation warnings\n",
    "_denoise_wavelet = partial(denoise_wavelet, rescale_sigma=True)\n",
    "import scipy.stats as stats\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "def rescale(dat,mn,mx):\n",
    "    \"\"\"\n",
    "    rescales an input dat between mn and mx\n",
    "    \"\"\"\n",
    "    m = min(dat.flatten())\n",
    "    M = max(dat.flatten())\n",
    "    return (mx-mn)*(dat-m)/(M-m)+mn\n",
    "\n",
    "##====================================\n",
    "def standardize(img):\n",
    "    img = np.array(img)\n",
    "    #standardization using adjusted standard deviation\n",
    "    N = np.shape(img)[0] * np.shape(img)[1]\n",
    "    s = np.maximum(np.std(img), 1.0/np.sqrt(N))\n",
    "    m = np.mean(img)\n",
    "    img = (img - m) / s\n",
    "    img = rescale(img, 0, 1)\n",
    "    del m, s, N\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image= \"C_1.jpg\"\n",
    "resolution = 0.053819445\n",
    "img = cv2.imread(image)\n",
    "nxx, nyy, _ = img.shape\n",
    "width = max(nxx, nyy)\n",
    "maxscale= width*resolution / 8\n",
    "\n",
    "x= 0\n",
    "verbose = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stage 1: read image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = imread(image)   # read the image straight with imread\n",
    "im = np.squeeze(im)  # squeeze singleton dimensions\n",
    "if len(np.shape(im))>3:\n",
    "    im = im[:, :, :3]            # only keep the first 3 bands\n",
    "\n",
    "if len(np.shape(im))==3: # if rgb, convert to grey\n",
    "    im = (0.299 * im[:,:,0] + 0.5870*im[:,:,1] + 0.114*im[:,:,2]).astype('uint8')\n",
    "\n",
    "nx,ny = np.shape(im)\n",
    "if nx>ny:\n",
    "    im=im.T\n",
    "\n",
    "im = standardize(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stage 2: Denoised image using default parameters of `denoise_wavelet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter=False\n",
    "\n",
    "if filter:\n",
    "    sigma_est = estimate_sigma(im, multichannel=False, average_sigmas=True)\n",
    "    region = denoise_wavelet(im, multichannel=False, rescale_sigma=True,\n",
    "                                method='VisuShrink', mode='soft', sigma=sigma_est*2)\n",
    "else:\n",
    "    region = im.copy()\n",
    "\n",
    "original = rescale(region,0,255)\n",
    "\n",
    "nx, ny = original.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stage 3: Call cwt to get particle size distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_og = []; M_og = []; Power = []; frequencie = []\n",
    "for k in np.linspace(1,nx-1,100):\n",
    "    [cfs_og, frequencies_og] = pywt.cwt(original[int(k),:], np.arange(3, np.maximum(nx,ny)/maxscale, 1),  'morl' , .5) #cmor10-8\n",
    "    period_og = 1. / frequencies_og\n",
    "    frequencie.append(period_og)\n",
    "    power_og =(abs(cfs_og)) ** 2\n",
    "    Power.append(power_og)\n",
    "    power_og = np.mean(np.abs(power_og), axis=1)/(period_og**2)\n",
    "    P_og.append(power_og)\n",
    "\n",
    "    M_og.append(period_og[np.argmax(power_og)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 146, 2668)\n",
      "(100, 146)\n",
      "2.4615384615384617\n",
      "2.4615384615384617\n"
     ]
    }
   ],
   "source": [
    "frequencie = np.array(frequencie)\n",
    "Power = np.array(Power)\n",
    "print(np.shape(Power)); print(np.shape(frequencie))\n",
    "print(np.mean(frequencie))\n",
    "\n",
    "# plt.plot(frequencies_og, power_og)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_og = np.mean(np.vstack(P_og), axis=0)\n",
    "p_og = np.array(p_og/np.sum(p_og))\n",
    "\n",
    "# get real scales by multiplying by resolution (mm/pixel)\n",
    "scales_og = np.array(period_og)\n",
    "\n",
    "srt_og = np.sqrt(np.sum(p_og*((scales_og-np.mean(M_og))**2)))\n",
    "\n",
    "# plt.plot(scales, p,'m', lw=2)\n",
    "\n",
    "p_og = p_og+stats.norm.pdf(scales_og, np.mean(M_og), srt_og/2)\n",
    "p_og = np.hstack([0,p_og])\n",
    "scales_og = np.hstack([0,scales_og])\n",
    "p_og = p_og/np.sum(p_og)\n",
    "x_og = 0\n",
    "# area-by-number to volume-by-number\n",
    "r_v_og = (p_og*scales_og**x_og) / np.sum(p_og*scales_og**x_og) #volume-by-weight proportion\n",
    "\n",
    "plt.plot((scales_og*resolution), r_v_og)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scales_og*resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(r_v_og[0:45]))\n",
    "print(np.trapz(r_v_og[0:45], scales_og[0:45]))\n",
    "print(np.sqrt(np.trapz(r_v_og[0:59], scales_og[0:59])))\n",
    "print('dfew')\n",
    "\n",
    "print(np.sum(r_v_og[59:122]))\n",
    "print(np.trapz(r_v_og[45:122], scales_og[45:122]))\n",
    "print(np.sqrt(np.trapz(r_v_og[45:122], scales_og[45:122])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_og = np.interp([.05,.1,.16,.25,.3,.5,.75,.84,.9,.95],np.hstack((0,np.cumsum(r_v_og))), np.hstack((0,scales_og)) )\n",
    "data_C_og = pd_og * resolution\n",
    "\n",
    "sieve_open = [8, 4, 2, 1, 0.71, 0.5, 0.425, 0.355, 0.3, 0.25, 0.18, 0.125, 0.063]\n",
    "sieve_C = [98, 93, 76, 55, 40, 22, 16, 9, 5, 2, 0, 0, 0]\n",
    "sieve_A = [100, 100, 100, 99, 97, 90, 85, 76, 64, 44, 18, 2, 0]\n",
    "percentile_C = [5, 10, 16, 25, 30, 50,  75, 84, 90, 95] \n",
    "plt.plot(data_C_og, percentile_C, marker='.')\n",
    "plt.plot(sieve_open, sieve_C, ls='--', color='black')\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.grid(which='major', linewidth=2, linestyle='-')\n",
    "plt.grid(which='minor', linewidth=1, linestyle='--')\n",
    "plt.yticks(np.arange(0,110, 10), ['0', '10', '20', '30', '40', '50', '60', '70', '80', '90', '100'] )\n",
    "plt.xticks([0.1, 1, 10], [0.1,1,10])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stage 5: Calc particle size stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd = np.interp([.05,.1,.16,.25,.3,.5,.75,.84,.9,.95],np.hstack((0,np.cumsum(r_v))), np.hstack((0,scales)) )\n",
    "pd *= resolution\n",
    "if verbose==1:\n",
    "    print(\"d50 = \"+str(pd[5]))\n",
    "\n",
    "mnsz = np.sum(r_v*scales)\n",
    "if verbose==1:\n",
    "    print(\"mean size = \"+str(mnsz))\n",
    "\n",
    "srt = np.sqrt(np.sum(r_v*((scales-mnsz)**2)))\n",
    "if verbose==1:\n",
    "    print(\"stdev = \"+str(srt))\n",
    "\n",
    "sk = (sum(r_v*((scales-mnsz)**3)))/(100*srt**3)\n",
    "if verbose==1:\n",
    "    print(\"skewness = \"+str(sk))\n",
    "\n",
    "kurt = (sum(r_v*((scales-mnsz)**4)))/(100*srt**4)\n",
    "if verbose==1:\n",
    "    print(\"kurtosis = \"+str(kurt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stage 6: Return a dict object of stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( {'mean grain size': mnsz, 'grain size sorting': srt, 'grain size skewness': sk, 'grain size kurtosis': kurt, \n",
    "        'percentiles': [.05,.1,.16,.25,.3,.5,.75,.84,.9,.95], 'percentile_values': pd, 'grain size frequencies': r_v, 'grain size bins': scales})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scales*resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = []; M = []\n",
    "for k in np.linspace(1,nx-1,100):\n",
    "    [cfs, frequencies] = pywt.cwt(original[int(k),:], np.arange(3 , np.maximum(nx,ny)/maxscale, 1),  'cmor10000-0.17', .5) \n",
    "    # np.arange(3, np.maximum(nx,ny)/maxscale, 1), 'cmor2-0.65', .5\n",
    "  \n",
    "    period = 1. / frequencies\n",
    "    power =(abs(cfs)) ** 2\n",
    "    power = np.mean(np.abs(power), axis=1)/(period**2)\n",
    "    P.append(power)\n",
    "\n",
    "    M.append(period[np.argmax(power)])\n",
    "\n",
    "p = np.mean(np.vstack(P), axis=0)\n",
    "p = np.array(p/np.sum(p))\n",
    "\n",
    "# get real scales by multiplying by resolution (mm/pixel)\n",
    "scales = np.array(period)\n",
    "\n",
    "srt = np.sqrt(np.sum(p*((scales-np.mean(M))**2)))\n",
    "\n",
    "# plt.plot(scales, p,'m', lw=2)\n",
    "\n",
    "p = p+stats.norm.pdf(scales, np.mean(M), srt/2)\n",
    "p = np.hstack([0,p])\n",
    "scales = np.hstack([0,scales])\n",
    "p = p/np.sum(p)\n",
    "x = 0\n",
    "# area-by-number to volume-by-number\n",
    "r_v = (p*scales**x) / np.sum(p*scales**x) #volume-by-weight proportion\n",
    "\n",
    "pd = np.interp([.05,.1,.16,.25,.3,.5,.75,.84,.9,.95],np.hstack((0,np.cumsum(r_v))), np.hstack((0,scales)) )\n",
    "data_C = pd * resolution\n",
    "sieve_open = [8, 4, 2, 1, 0.71, 0.5, 0.425, 0.355, 0.3, 0.25, 0.18, 0.125, 0.063]\n",
    "sieve_C = [98, 93, 76, 55, 40, 22, 16, 9, 5, 2, 0, 0, 0]\n",
    "sieve_A = [100, 100, 100, 99, 97, 90, 85, 76, 64, 44, 18, 2, 0]\n",
    "percentile_C = [5, 10, 16, 25, 30, 50,  75, 84, 90, 95] \n",
    "plt.plot(data_C, percentile_C, marker='.')\n",
    "plt.plot(sieve_open, sieve_C, ls='--', color='black')\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.grid(which='major', linewidth=2, linestyle='-')\n",
    "plt.grid(which='minor', linewidth=1, linestyle='--')\n",
    "plt.yticks(np.arange(0,110, 10), ['0', '1210', '20', '30', '40', '50', '60', '70', '80', '90', '100'] )\n",
    "plt.xticks([0.1, 1, 10], [0.1,1,10])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = []; M = []\n",
    "for k in np.linspace(1,nx-1,100):\n",
    "    [cfs, frequencies] = pywt.cwt(original[int(k),:], np.arange(np.maximum(nx,ny)/(width*resolution / .1) ,  np.maximum(nx,ny)/(width*resolution / 2), 1),  'cmor10000-0.70', .5) #cmor10-8\n",
    "      \n",
    "    period = 1. / frequencies\n",
    "    power =(abs(cfs)) ** 2\n",
    "    power = np.mean(np.abs(power), axis=1)/(period**2)\n",
    "    P.append(power)\n",
    "\n",
    "    M.append(period[np.argmax(power)])\n",
    "\n",
    "p = np.mean(np.vstack(P), axis=0)\n",
    "p = np.array(p/np.sum(p))\n",
    "\n",
    "# get real scales by multiplying by resolution (mm/pixel)\n",
    "scales = np.array(period)\n",
    "\n",
    "srt = np.sqrt(np.sum(p*((scales-np.mean(M))**2)))\n",
    "\n",
    "# plt.plot(scales, p,'m', lw=2)\n",
    "\n",
    "p = p+stats.norm.pdf(scales, np.mean(M), srt/2)\n",
    "p = np.hstack([0,p])\n",
    "scales = np.hstack([0,scales])\n",
    "p = p/np.sum(p)\n",
    "x = 0\n",
    "# area-by-number to volume-by-number\n",
    "r_v = (p*scales**x) / np.sum(p*scales**x) #volume-by-weight proportion\n",
    "\n",
    "pd = np.interp([.05,.1,.16,.25,.3,.5,.75,.84,.9,.95],np.hstack((0,np.cumsum(r_v))), np.hstack((0,scales)) )\n",
    "data_C = pd * resolution\n",
    "sieve_open = [8, 4, 2, 1, 0.71, 0.5, 0.425, 0.355, 0.3, 0.25, 0.18, 0.125, 0.063]\n",
    "sieve_C = [98, 93, 76, 55, 40, 22, 16, 9, 5, 2, 0, 0, 0]\n",
    "sieve_A = [100, 100, 100, 99, 97, 90, 85, 76, 64, 44, 18, 2, 0]\n",
    "percentile_C = [5, 10, 16, 25, 30, 50,  75, 84, 90, 95] \n",
    "plt.plot(data_C, percentile_C, marker='.')\n",
    "plt.plot(sieve_open, sieve_C, ls='--', color='black')\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.grid(which='major', linewidth=2, linestyle='-')\n",
    "plt.grid(which='minor', linewidth=1, linestyle='--')\n",
    "plt.yticks(np.arange(0,110, 10), ['0', '1210', '20', '30', '40', '50', '60', '70', '80', '90', '100'] )\n",
    "plt.xticks([0.1, 1, 10], [0.1,1,10])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = []; M = []\n",
    "for k in np.linspace(1,nx-1,100):\n",
    "    [cfs, frequencies] = pywt.cwt(original[int(k),:], np.arange(np.maximum(nx,ny)/(width*resolution / .1) ,  np.maximum(nx,ny)/(width*resolution / 2), 1),  'cmor1-0.23', 1) #cmor10-8\n",
    "    period = 1. / frequencies\n",
    "    power =(abs(cfs)) ** 2\n",
    "    power = np.mean(np.abs(power), axis=1)/(period**2)\n",
    "    P.append(power)\n",
    "\n",
    "    M.append(period[np.argmax(power)])\n",
    "\n",
    "p = np.mean(np.vstack(P), axis=0)\n",
    "p = np.array(p/np.sum(p))\n",
    "\n",
    "# get real scales by multiplying by resolution (mm/pixel)\n",
    "scales = np.array(period)\n",
    "\n",
    "srt = np.sqrt(np.sum(p*((scales-np.mean(M))**2)))\n",
    "\n",
    "# plt.plot(scales, p,'m', lw=2)\n",
    "\n",
    "p = p+stats.norm.pdf(scales, np.mean(M), srt/2)\n",
    "p = np.hstack([0,p])\n",
    "scales = np.hstack([0,scales])\n",
    "p = p/np.sum(p)\n",
    "x = 0\n",
    "# area-by-number to volume-by-number\n",
    "r_v = (p*scales**x) / np.sum(p*scales**x) #volume-by-weight proportion\n",
    "\n",
    "pd = np.interp([.05,.1,.16,.25,.3,.4,.5,.6,.75,.84,.9,.95],np.hstack((0,np.cumsum(r_v))), np.hstack((0,scales)) )\n",
    "data_C = pd * resolution\n",
    "sieve_open = [8, 4, 2, 1, 0.71, 0.5, 0.425, 0.355, 0.3, 0.25, 0.18, 0.125, 0.063]\n",
    "sieve_C = [98, 93, 76, 55, 40, 22, 16, 9, 5, 2, 0, 0, 0]\n",
    "percentile_C = [5, 10, 16, 25, 30, 40, 50, 60, 75, 84, 90, 95] \n",
    "plt.plot(data_C, percentile_C, marker='.')\n",
    "plt.plot(sieve_open, sieve_C, ls='--', color='black')\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.grid(which='major', linewidth=2, linestyle='-')\n",
    "plt.grid(which='minor', linewidth=1, linestyle='--')\n",
    "plt.yticks(np.arange(0,110, 10), ['0', '10', '20', '30', '40', '50', '60', '70', '80', '90', '100'] )\n",
    "plt.xticks([0.1, 1, 10], [0.1,1,10])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEwe wiueB efewsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = []; M = []\n",
    "for k in np.linspace(1,nx-1,100):\n",
    "    [cfs, frequencies] = pywt.cwt(original[int(k),:], np.arange(np.maximum(nx,ny)/(width*resolution / .1) ,  np.maximum(nx,ny)/(width*resolution / 1), 1),  'morl', .5) #cmor10-8\n",
    "    period = 1. / frequencies\n",
    "    power =(abs(cfs)) ** 2\n",
    "    power = np.mean(np.abs(power), axis=1)/(period**2)\n",
    "    P.append(power)\n",
    "\n",
    "    M.append(period[np.argmax(power)])\n",
    "\n",
    "p = np.mean(np.vstack(P), axis=0)\n",
    "p = np.array(p/np.sum(p))\n",
    "\n",
    "# get real scales by multiplying by resolution (mm/pixel)\n",
    "scales = np.array(period)\n",
    "\n",
    "srt = np.sqrt(np.sum(p*((scales-np.mean(M))**2)))\n",
    "\n",
    "# plt.plot(scales, p,'m', lw=2)\n",
    "\n",
    "p = p+stats.norm.pdf(scales, np.mean(M), srt/2)\n",
    "p = np.hstack([0,p])\n",
    "scales = np.hstack([0,scales])\n",
    "p = p/np.sum(p)\n",
    "x = 0\n",
    "# area-by-number to volume-by-number\n",
    "r_v = (p*scales**x) / np.sum(p*scales**x) #volume-by-weight proportion\n",
    "\n",
    "pd = np.interp([.05,.1,.16,.25,.3,.4,.5,.6,.75,.84,.9,.95],np.hstack((0,np.cumsum(r_v))), np.hstack((0,scales)) )\n",
    "data_C = pd * resolution\n",
    "sieve_open = [8, 4, 2, 1, 0.71, 0.5, 0.425, 0.355, 0.3, 0.25, 0.18, 0.125, 0.063]\n",
    "sieve_C = [98, 93, 76, 55, 40, 22, 16, 9, 5, 2, 0, 0, 0]\n",
    "percentile_C = [5, 10, 16, 25, 30, 40, 50, 60, 75, 84, 90, 95] \n",
    "plt.plot(data_C, percentile_C, marker='.')\n",
    "plt.plot(sieve_open, sieve_C, ls='--', color='black')\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.grid(which='major', linewidth=2, linestyle='-')\n",
    "plt.grid(which='minor', linewidth=1, linestyle='--')\n",
    "plt.yticks(np.arange(0,110, 10), ['0', '10', '20', '30', '40', '50', '60', '70', '80', '90', '100'] )\n",
    "plt.xticks([0.1, 1, 10], [0.1,1,10])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = []; M = []\n",
    "for k in np.linspace(1,nx-1,100):\n",
    "    [cfs, frequencies] = pywt.cwt(original[int(k),:], np.arange(3,  np.maximum(nx,ny)/(maxscale), .1),  'morl', .5) #cmor10-8\n",
    "    period = 1. / frequencies\n",
    "    power =(abs(cfs)) ** 2\n",
    "    power = np.mean(np.abs(power), axis=1)/(period**2)\n",
    "    P.append(power)\n",
    "\n",
    "    M.append(period[np.argmax(power)])\n",
    "\n",
    "p = np.mean(np.vstack(P), axis=0)\n",
    "p = np.array(p/np.sum(p))\n",
    "\n",
    "# get real scales by multiplying by resolution (mm/pixel)\n",
    "scales = np.array(period)\n",
    "\n",
    "srt = np.sqrt(np.sum(p*((scales-np.mean(M))**2)))\n",
    "\n",
    "# plt.plot(scales, p,'m', lw=2)\n",
    "\n",
    "p = p+stats.norm.pdf(scales, np.mean(M), srt/2)\n",
    "p = np.hstack([0,p])\n",
    "scales = np.hstack([0,scales])\n",
    "p = p/np.sum(p)\n",
    "x = 0\n",
    "# area-by-number to volume-by-number\n",
    "r_v = (p*scales**x) / np.sum(p*scales**x) #volume-by-weight proportion\n",
    "\n",
    "pd = np.interp([.05,.1,.16,.25,.3,.4,.5,.6,.75,.84,.9,.95],np.hstack((0,np.cumsum(r_v))), np.hstack((0,scales)) )\n",
    "data_C = pd * resolution\n",
    "sieve_open = [8, 4, 2, 1, 0.71, 0.5, 0.425, 0.355, 0.3, 0.25, 0.18, 0.125, 0.063]\n",
    "sieve_C = [98, 93, 76, 55, 40, 22, 16, 9, 5, 2, 0, 0, 0]\n",
    "percentile_C = [5, 10, 16, 25, 30, 40, 50, 60, 75, 84, 90, 95] \n",
    "plt.plot(data_C, percentile_C, marker='.')\n",
    "plt.plot(sieve_open, sieve_C, ls='--', color='black')\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.grid(which='major', linewidth=2, linestyle='-')\n",
    "plt.grid(which='minor', linewidth=1, linestyle='--')\n",
    "plt.yticks(np.arange(0,110, 10), ['0', '10', '20', '30', '40', '50', '60', '70', '80', '90', '100'] )\n",
    "plt.xticks([0.1, 1, 10], [0.1,1,10])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = []; M = []\n",
    "for k in np.linspace(1,nx-1,100):\n",
    "    [cfs, frequencies] = pywt.cwt(original[int(k),:], np.arange(3,  np.maximum(nx,ny)/(maxscale), 2),  'morl', .5) #cmor10-8\n",
    "    period = 1. / frequencies\n",
    "    power =(abs(cfs)) ** 2\n",
    "    power = np.mean(np.abs(power), axis=1)/(period**2)\n",
    "    P.append(power)\n",
    "\n",
    "    M.append(period[np.argmax(power)])\n",
    "\n",
    "p = np.mean(np.vstack(P), axis=0)\n",
    "p = np.array(p/np.sum(p))\n",
    "\n",
    "# get real scales by multiplying by resolution (mm/pixel)\n",
    "scales = np.array(period)\n",
    "\n",
    "srt = np.sqrt(np.sum(p*((scales-np.mean(M))**2)))\n",
    "\n",
    "# plt.plot(scales, p,'m', lw=2)\n",
    "\n",
    "p = p+stats.norm.pdf(scales, np.mean(M), srt/2)\n",
    "p = np.hstack([0,p])\n",
    "scales = np.hstack([0,scales])\n",
    "p = p/np.sum(p)\n",
    "x = 0\n",
    "# area-by-number to volume-by-number\n",
    "r_v = (p*scales**x) / np.sum(p*scales**x) #volume-by-weight proportion\n",
    "\n",
    "pd = np.interp([.05,.1,.16,.25,.3,.4,.5,.6,.75,.84,.9,.95],np.hstack((0,np.cumsum(r_v))), np.hstack((0,scales)) )\n",
    "data_C = pd * resolution\n",
    "sieve_open = [8, 4, 2, 1, 0.71, 0.5, 0.425, 0.355, 0.3, 0.25, 0.18, 0.125, 0.063]\n",
    "sieve_C = [98, 93, 76, 55, 40, 22, 16, 9, 5, 2, 0, 0, 0]\n",
    "percentile_C = [5, 10, 16, 25, 30, 40, 50, 60, 75, 84, 90, 95] \n",
    "plt.plot(data_C, percentile_C, marker='.')\n",
    "plt.plot(sieve_open, sieve_C, ls='--', color='black')\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.grid(which='major', linewidth=2, linestyle='-')\n",
    "plt.grid(which='minor', linewidth=1, linestyle='--')\n",
    "plt.yticks(np.arange(0,110, 10), ['0', '10', '20', '30', '40', '50', '60', '70', '80', '90', '100'] )\n",
    "plt.xticks([0.1, 1, 10], [0.1,1,10])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
